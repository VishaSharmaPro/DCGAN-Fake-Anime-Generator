{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11212164,"sourceType":"datasetVersion","datasetId":7001145}],"dockerImageVersionId":30918,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport warnings\nfrom tqdm.notebook import tqdm\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import load_img, array_to_img\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import BinaryCrossentropy\n\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T05:26:55.315728Z","iopub.execute_input":"2025-05-01T05:26:55.316005Z","iopub.status.idle":"2025-05-01T05:27:07.553576Z","shell.execute_reply.started":"2025-05-01T05:26:55.315975Z","shell.execute_reply":"2025-05-01T05:27:07.552658Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Load the files","metadata":{}},{"cell_type":"code","source":"BASEDIR = \"/kaggle/input/anime-faces/data\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T05:27:07.555334Z","iopub.execute_input":"2025-05-01T05:27:07.555909Z","iopub.status.idle":"2025-05-01T05:27:07.559256Z","shell.execute_reply.started":"2025-05-01T05:27:07.555883Z","shell.execute_reply":"2025-05-01T05:27:07.558404Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# load complete image path to list\nimage_paths = []\nfor imagename in os.listdir(BASEDIR):\n    image_path = os.path.join(BASEDIR, imagename)\n    image_paths.append(image_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T05:27:07.560505Z","iopub.execute_input":"2025-05-01T05:27:07.560815Z","iopub.status.idle":"2025-05-01T05:27:07.738819Z","shell.execute_reply.started":"2025-05-01T05:27:07.560785Z","shell.execute_reply":"2025-05-01T05:27:07.738165Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(image_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T05:27:07.739486Z","iopub.execute_input":"2025-05-01T05:27:07.739705Z","iopub.status.idle":"2025-05-01T05:27:07.743957Z","shell.execute_reply.started":"2025-05-01T05:27:07.739686Z","shell.execute_reply":"2025-05-01T05:27:07.743176Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image_paths[:5]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T05:27:07.744621Z","iopub.execute_input":"2025-05-01T05:27:07.744848Z","iopub.status.idle":"2025-05-01T05:27:07.760215Z","shell.execute_reply.started":"2025-05-01T05:27:07.744828Z","shell.execute_reply":"2025-05-01T05:27:07.759415Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(image_paths)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T05:27:07.762391Z","iopub.execute_input":"2025-05-01T05:27:07.762618Z","iopub.status.idle":"2025-05-01T05:27:07.773664Z","shell.execute_reply.started":"2025-05-01T05:27:07.762599Z","shell.execute_reply":"2025-05-01T05:27:07.773031Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# remove unnecessary file\nimage_paths.remove('/kaggle/input/anime-faces/data/data')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T05:27:07.775216Z","iopub.execute_input":"2025-05-01T05:27:07.775440Z","iopub.status.idle":"2025-05-01T05:27:07.787462Z","shell.execute_reply.started":"2025-05-01T05:27:07.775422Z","shell.execute_reply":"2025-05-01T05:27:07.786748Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(image_paths)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T05:27:07.788171Z","iopub.execute_input":"2025-05-01T05:27:07.788403Z","iopub.status.idle":"2025-05-01T05:27:07.802639Z","shell.execute_reply.started":"2025-05-01T05:27:07.788379Z","shell.execute_reply":"2025-05-01T05:27:07.801955Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Visualize the Image Dataset","metadata":{}},{"cell_type":"code","source":"# to display grid of images(7x7)\nplt.figure(figsize = (20,20))\ntempimages = image_paths[:49]\nindex = 1\n\nfor image_path in tempimages:\n    plt.subplot(7,7,index)\n    #load the image\n    img = load_img(image_path)\n    #convert to numpy array\n    img = np.array(img)\n    plt.imshow(img)\n    plt.axis('off')\n    #increment the index for next image\n    index += 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T05:27:07.803359Z","iopub.execute_input":"2025-05-01T05:27:07.803635Z","iopub.status.idle":"2025-05-01T05:27:10.432696Z","shell.execute_reply.started":"2025-05-01T05:27:07.803608Z","shell.execute_reply":"2025-05-01T05:27:10.431665Z"}},"outputs":[],"execution_count":null},{"cell_type":"raw","source":"# Preprocess Image","metadata":{}},{"cell_type":"code","source":"# Load the image and convert to numpy array\ntrainimages = [np.array(load_img(path)) for path in tqdm(image_paths)]   # pehla vala np.array ek image ke pixel ka numpy array bana ta hai\nprint(trainimages[0])\ntrainimages = np.array(trainimages) #  dusra vala  saari images  ka numpy array banata hai","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T05:27:10.433815Z","iopub.execute_input":"2025-05-01T05:27:10.434242Z","iopub.status.idle":"2025-05-01T05:28:38.991529Z","shell.execute_reply.started":"2025-05-01T05:27:10.434203Z","shell.execute_reply":"2025-05-01T05:28:38.990705Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(trainimages[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T05:28:38.992239Z","iopub.execute_input":"2025-05-01T05:28:38.992458Z","iopub.status.idle":"2025-05-01T05:28:38.997497Z","shell.execute_reply.started":"2025-05-01T05:28:38.992438Z","shell.execute_reply":"2025-05-01T05:28:38.996477Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainimages.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T05:28:38.998357Z","iopub.execute_input":"2025-05-01T05:28:38.998599Z","iopub.status.idle":"2025-05-01T05:28:39.015051Z","shell.execute_reply.started":"2025-05-01T05:28:38.998566Z","shell.execute_reply":"2025-05-01T05:28:39.014281Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainimages[0].shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T05:28:39.015841Z","iopub.execute_input":"2025-05-01T05:28:39.016095Z","iopub.status.idle":"2025-05-01T05:28:39.033301Z","shell.execute_reply.started":"2025-05-01T05:28:39.016072Z","shell.execute_reply":"2025-05-01T05:28:39.032700Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#reshape the array \ntrainimages = trainimages.reshape(trainimages.shape[0],64,64,3).astype('float32')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T05:28:39.033944Z","iopub.execute_input":"2025-05-01T05:28:39.034157Z","iopub.status.idle":"2025-05-01T05:28:39.297300Z","shell.execute_reply.started":"2025-05-01T05:28:39.034133Z","shell.execute_reply":"2025-05-01T05:28:39.296551Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# normalize the images\ntrainimages = (trainimages - 127.5) / 127.5\n\n# yahan par hum normalization mei values ko (-1 to 1) kar rahe hain (0 to 1) nahi kar rahe hain kyunki hum activation function function \"tanh\" use karenge jo ki -1 to 1 demand karta hai","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T05:28:39.298135Z","iopub.execute_input":"2025-05-01T05:28:39.298337Z","iopub.status.idle":"2025-05-01T05:28:39.730836Z","shell.execute_reply.started":"2025-05-01T05:28:39.298319Z","shell.execute_reply":"2025-05-01T05:28:39.730164Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainimages[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T05:28:39.731511Z","iopub.execute_input":"2025-05-01T05:28:39.731710Z","iopub.status.idle":"2025-05-01T05:28:39.737912Z","shell.execute_reply.started":"2025-05-01T05:28:39.731692Z","shell.execute_reply":"2025-05-01T05:28:39.736992Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Create Generator and Discriminator","metadata":{}},{"cell_type":"code","source":"# latent dimension for random noise\n\nLatentDIM = 100   # agar latentdim kam rakhegne jaise ki 10 toh image ke produce hone ki variety less hogi and aga jayada rakhenge jaise 200 toh variety increase hogi\n\n# weight initializer\nWeightInit = keras.initializers.RandomNormal(mean = 0.0 , stddev = 0.02)\n\n# number of channels of the image\nChannels = 3  # because of RGB\n\n# Mean = 0.0 → \"Average salary\" zero rakho\n# Stddev = 0.02 → \"Salary range\" bahut chhota rakho (±0.04 ke around)\n\n# Galat Tarika : Kisi ko ₹1,00,000 salary, kisi ko ₹500 dena → System fail!\n# Sahi Tarika (stddev=0.02) : Sabko ₹9,800-₹10,200 ke beech salary dena → Stable system\n# Zyada bade weights → Network fail ho jata hai, Chhote weights se model aram se seekhta hai\n\n# Kyun Mean=0? = Balance Ke Liye: Positive/Negative dono tarah ke connections ban paaye ,Jaise company me HR aur IT dono departments ka balance","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T05:28:39.738809Z","iopub.execute_input":"2025-05-01T05:28:39.739011Z","iopub.status.idle":"2025-05-01T05:28:39.750644Z","shell.execute_reply.started":"2025-05-01T05:28:39.738994Z","shell.execute_reply":"2025-05-01T05:28:39.749812Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Generator Model\n\nGenerator model will create new images similar to training data from random noise","metadata":{}},{"cell_type":"code","source":"model = Sequential(name = 'generator')\n\n# 1d random noise\n\nmodel.add(layers.Dense(8 * 8 * 512, input_dim = LatentDIM))\n\n#model.add(layers.BatchNormalization())\nmodel.add(layers.ReLU())\n\n# convert 1d to 3d\nmodel.add(layers.Reshape((8,8,512)))\n\n\n# umsample to 16 x 16\n\nmodel.add(layers.Conv2DTranspose(256, (4,4), strides = (2,2), padding = 'same',kernel_initializer = WeightInit))          \n#model.add(layers.BatchNormalization())\nmodel.add(layers.ReLU())\n\n\n# umsample to 32 x 32\n\nmodel.add(layers.Conv2DTranspose(128, (4,4), strides = (2,2), padding = 'same',kernel_initializer = WeightInit))          \n#model.add(layers.BatchNormalization())\nmodel.add(layers.ReLU())\n\n# umsample to 64 x 64\n\nmodel.add(layers.Conv2DTranspose(64, (4,4), strides = (2,2), padding = 'same',kernel_initializer = WeightInit))          \n#model.add(layers.BatchNormalization())\nmodel.add(layers.ReLU())\n\n\nmodel.add(layers.Conv2D(Channels, (4,4), padding ='same', activation = 'tanh'))\n\ngenerator = model\ngenerator.summary()\n\n# conv2DTranspose() upsampling ke liye hota hai jabki conv2d downsampling ke liye use hoti hai\n# Yeh 2 lines ka matlab hai:\n\n# Pehle ek dense layer se 1D noise vector (size LatentDIM, jaise 100) ko convert kiya 8×8×512 neurons mein (matlab total 32768 units).\n\n# Phir usko 3D tensor mein reshape kiya: (8, 8, 512) → jaise image feature map ban gaya ho.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T05:28:39.753784Z","iopub.execute_input":"2025-05-01T05:28:39.754043Z","iopub.status.idle":"2025-05-01T05:28:41.917363Z","shell.execute_reply.started":"2025-05-01T05:28:39.754023Z","shell.execute_reply":"2025-05-01T05:28:41.916611Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Discriminator Model\n\nDiscriminator model will classify the images from the generator to check whether it is real or fake images","metadata":{}},{"cell_type":"code","source":"model = Sequential(name = 'discriminator')\ninput_shape = (64,64,3)\n\nalpha = 0.2\n\n\n# create conv layers\nmodel.add(layers.Conv2D(64, (4,4), strides = (2,2), padding = 'same', input_shape = input_shape))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.LeakyReLU(alpha = alpha))\n\n# downsampling the images\nmodel.add(layers.Conv2D(128, (4,4), strides = (2,2), padding = 'same', input_shape = input_shape))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.LeakyReLU(alpha = alpha))\n\nmodel.add(layers.Conv2D(128, (4,4), strides = (2,2), padding = 'same', input_shape = input_shape))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.LeakyReLU(alpha = alpha))\n\nmodel.add(layers.Flatten())\nmodel.add(layers.Dropout(0.3))\n\n\n# output class \nmodel.add(layers.Dense(1,activation = 'sigmoid'))\n\ndiscriminator = model\ndiscriminator.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T05:28:41.918516Z","iopub.execute_input":"2025-05-01T05:28:41.918733Z","iopub.status.idle":"2025-05-01T05:28:42.257839Z","shell.execute_reply.started":"2025-05-01T05:28:41.918714Z","shell.execute_reply":"2025-05-01T05:28:42.257170Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Create DCGAN","metadata":{}},{"cell_type":"code","source":"class DCGAN(keras.Model):\n    def __init__(self, generator, discriminator, LatentDIM):\n        super().__init__()\n        self.generator = generator\n        self.discriminator = discriminator\n        self.LatentDIM = LatentDIM\n        self.g_loss_metric = keras.metrics.Mean(name = 'g_loss')\n        self.d_loss_metric = keras.metrics.Mean(name = 'd_loss')\n\n    @property\n    def metrics(self):\n        return [self.g_loss_metric, self.d_loss_metric]\n\n    def compile(self, g_optimizer, d_optimizer, loss_fn):\n        super(DCGAN, self).compile()\n        self.g_optimizer = g_optimizer\n        self.d_optimizer = d_optimizer\n        self.loss_fn = loss_fn\n\n    def train_step(self, real_images):\n        # get batch size from data\n        batch_size = tf.shape(real_images)[0]\n\n        #generate random noise\n        random_noise = tf.random.normal(shape = (batch_size, self.LatentDIM))\n\n        # train the discriminator with real(1) and fake(0) images\n        with tf.GradientTape() as tape:\n            #compute loss on real images\n            pred_real = self.discriminator(real_images, training = True)\n\n            # generate real images labels\n            real_labels = tf.ones((batch_size, 1))\n            # label smoothing\n            real_labels += 0.05 * tf.random.uniform(tf.shape(real_labels))\n\n            d_loss_real = self.loss_fn(real_labels, pred_real)\n\n            #compute loss on fake images\n            fake_images = self.generator(random_noise)\n            pred_fake = self.discriminator(fake_images, training = True)\n\n            #generate fake labels\n            fake_labels = tf.zeros((batch_size,1))\n            d_loss_fake = self.loss_fn(fake_labels,pred_fake)\n\n            #Agar fake pe bhi noise daaloge (0 ± 0.05), toh generator confuse hoga ki \"thoda fake chal jayega\" . real_labels pe chal jaata hai kyunuki thodi kum real image chalegi.\n\n            # total discriminator loss \n            d_loss = (d_loss_real + d_loss_fake) / 2\n\n\n        # compute discriminator gradients\n        gradients = tape.gradient(d_loss, self.discriminator.trainable_variables)\n\n        # update the gradients\n        self.d_optimizer.apply_gradients(zip(gradients, self.discriminator.trainable_variables))\n\n        # train generator model\n        labels = tf.ones((batch_size,1))\n\n        # generator wants discriminator to think that fake images are real\n        with tf.GradientTape() as tape:\n            #generate fake images from generator\n            fake_images = self.generator(random_noise,training = True)\n\n            # classify images as real or fake\n            pred_fake = self.discriminator(fake_images,training = True)\n\n            # compute loss\n            g_loss = self.loss_fn(labels, pred_fake)\n\n        # compute gradients\n        gradients = tape.gradient(g_loss, self.generator.trainable_variables)\n\n        # update gradients\n        self.g_optimizer.apply_gradients(zip(gradients, self.generator.trainable_variables))\n\n        # update states for both models\n        self.d_loss_metric.update_state(d_loss)\n        self.g_loss_metric.update_state(g_loss)\n\n\n        return {'d_loss' : self.d_loss_metric.result(),'gloss': self.g_loss_metric.result()}\n            \n            \n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T05:28:42.258625Z","iopub.execute_input":"2025-05-01T05:28:42.258869Z","iopub.status.idle":"2025-05-01T05:28:42.267298Z","shell.execute_reply.started":"2025-05-01T05:28:42.258849Z","shell.execute_reply":"2025-05-01T05:28:42.266566Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class DCGANMonitor(keras.callbacks.Callback):\n    def __init__(self, num_imgs= 25, latent_dim = 100):\n        self.num_imgs = num_imgs\n        self.latent_dim = latent_dim\n\n        #create random noise for generating images\n        self.noise = tf.random.normal((25, latent_dim))\n\n    def on_epoch_end(self, epoch,logs = None):\n        # generate images from noise\n        g_img = self.model.generator(self.noise)\n        # denormalise images \n        g_img = (g_img * 127.5) + 127.5\n        g_img.numpy()\n\n        fig = plt.figure(figsize=(8,8))\n        for i in range(self.num_imgs):\n            plt.subplot(5,5,i+1)\n            img = array_to_img(g_img[i])\n            plt.imshow(img)\n            plt.axis('off')\n\n        plt.show()\n\n    def on_train_end(self,logs = None):\n        self.model.generator.save('generator.h5')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T05:28:42.268053Z","iopub.execute_input":"2025-05-01T05:28:42.268333Z","iopub.status.idle":"2025-05-01T05:28:42.284219Z","shell.execute_reply.started":"2025-05-01T05:28:42.268305Z","shell.execute_reply":"2025-05-01T05:28:42.283575Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dcgan = DCGAN( generator = generator ,discriminator = discriminator, LatentDIM=LatentDIM)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T05:28:42.284913Z","iopub.execute_input":"2025-05-01T05:28:42.285082Z","iopub.status.idle":"2025-05-01T05:28:42.307890Z","shell.execute_reply.started":"2025-05-01T05:28:42.285066Z","shell.execute_reply":"2025-05-01T05:28:42.307181Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"D_LR = 0.0001\nG_LR = 0.0003\n\n#generator ko yahan faster train kara ja raha hai jayada learning rate de kar kyunki discrimintor ka learning rate jyadda hogaya toh voh generator ko hamesha supress kardiya karega and generator kabhi discriminator ko fool nhi kar payega\n\ndcgan.compile(g_optimizer = Adam(learning_rate = G_LR, beta_1 = 0.5), d_optimizer = Adam(learning_rate = D_LR, beta_1 =0.5),loss_fn = BinaryCrossentropy())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T05:28:42.308554Z","iopub.execute_input":"2025-05-01T05:28:42.308810Z","iopub.status.idle":"2025-05-01T05:28:42.323700Z","shell.execute_reply.started":"2025-05-01T05:28:42.308783Z","shell.execute_reply":"2025-05-01T05:28:42.322922Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"N_EPOCHS = 40\ndcgan.fit(trainimages, epochs = N_EPOCHS, callbacks = [DCGANMonitor()])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T05:47:41.264706Z","iopub.execute_input":"2025-05-01T05:47:41.264988Z","iopub.status.idle":"2025-05-01T06:03:59.628005Z","shell.execute_reply.started":"2025-05-01T05:47:41.264966Z","shell.execute_reply":"2025-05-01T06:03:59.627195Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Generate New Anime Image","metadata":{}},{"cell_type":"code","source":"\nnoise = tf.random.normal((25, 100))\nfig = plt.figure(figsize = (2,2))\n # generate images from noise\ng_img = dcgan.generator(noise)\n# denormalise images \ng_img = (g_img * 127.5) + 127.5\ng_img.numpy()\n    \n           \n\nimg = array_to_img(g_img[0])\nplt.imshow(img)\nplt.axis('off')\n\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T06:05:08.147634Z","iopub.execute_input":"2025-05-01T06:05:08.147984Z","iopub.status.idle":"2025-05-01T06:05:08.205772Z","shell.execute_reply.started":"2025-05-01T06:05:08.147952Z","shell.execute_reply":"2025-05-01T06:05:08.204938Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"noise = tf.random.normal((25, 100))\nfig = plt.figure(figsize = (3,3))\n # generate images from noise\ng_img = dcgan.generator(noise)\n# denormalise images \ng_img = (g_img * 127.5) + 127.5\ng_img.numpy()\n    \n           \n\nimg = array_to_img(g_img[0])\nplt.imshow(img)\nplt.axis('off')\n\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T06:04:14.989456Z","iopub.execute_input":"2025-05-01T06:04:14.989746Z","iopub.status.idle":"2025-05-01T06:04:15.039300Z","shell.execute_reply.started":"2025-05-01T06:04:14.989722Z","shell.execute_reply":"2025-05-01T06:04:15.038430Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save models in Keras 3 format (.keras)\n# generator.save('generator.keras')\n# discriminator.save('discriminator.keras')\n\n# # या फिर पुराने H5 format में सेव करें\n# generator.save('generator.h5')\n# discriminator.save('discriminator.h5')\n\n# print(\"Models saved successfully!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# TensorFlow SavedModel format में सेव करें (सिर्फ .keras या .h5 की जगह folder नाम दें)\n# generator.save('generator')  # यह एक folder बनाएगा\n# discriminator.save('discriminator')  # यह एक folder बनाएगा\n\n# print(\"Models saved in TensorFlow SavedModel format!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# model.save(\"dcgan_model.h5\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import tensorflow as tf\n\n# # Load the saved Keras model\n# model = tf.keras.models.load_model(\"dcgan_model.h5\")\n\n# # Convert to TensorFlow Lite\n# converter = tf.lite.TFLiteConverter.from_keras_model(model)\n# tflite_model = converter.convert()\n\n# # Save the converted model\n# with open(\"dcgan_model.tflite\", \"wb\") as f:\n#     f.write(tflite_model)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nprint(\"tensorflow version of model = \",tf.__version__)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T09:25:36.409244Z","iopub.execute_input":"2025-05-30T09:25:36.409447Z","iopub.status.idle":"2025-05-30T09:25:48.350857Z","shell.execute_reply.started":"2025-05-30T09:25:36.409428Z","shell.execute_reply":"2025-05-30T09:25:48.349942Z"}},"outputs":[{"name":"stdout","text":"tensorflow version of model =  2.17.1\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import keras\nprint(\"keras version of model = \",keras.__version__)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T09:25:53.671914Z","iopub.execute_input":"2025-05-30T09:25:53.672223Z","iopub.status.idle":"2025-05-30T09:25:53.676952Z","shell.execute_reply.started":"2025-05-30T09:25:53.672200Z","shell.execute_reply":"2025-05-30T09:25:53.676258Z"}},"outputs":[{"name":"stdout","text":"keras version of model =  3.5.0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}